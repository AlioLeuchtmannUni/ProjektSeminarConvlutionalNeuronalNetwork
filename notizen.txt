# Ziel:

- Testen von djl am Beispiel ein CNN für mnist datensatz zu bauen
- Vorbild: Experiment1  https://www.kaggle.com/code/cdeotte/how-to-choose-cnn-architecture-mnist/notebook

## Analyse was passiert, Kommentierte Version des zu implementierenden Quellcodes

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import LearningRateScheduler
import matplotlib.pyplot as plt

# LOAD THE DATA

### ARCHITECTURE:
- 784 - [24C5-P2] - 256 - 10
- 784 - [24C5-P2] - [48C5-P2] - 256 - 10
- 784 - [24C5-P2] - [48C5-P2] - [64C5-P2] - 256 - 10

### LEGENDE:
- 24C5 means a convolution layer with 24 feature maps using a 5x5 filter and stride 1
- 24C5S2 means a convolution layer with 24 feature maps using a 5x5 filter and stride 2
- P2 means max pooling using 2x2 filter and stride 2
- 256 means fully connected dense layer with 256 units


### The input image is 28x28. After one pair, it's 14x14. After two, it's 7x7. After three it's 4x4
---> Wegen Pooling

#### Trainingsdaten
train = pd.read_csv("../input/train.csv")
#### Testdaten
test = pd.read_csv("../input/test.csv")

# PREPARE DATA FOR NEURAL NETWORK
Y_train = train["label"]
X_train = train.drop(labels = ["label"],axis = 1)
X_train = X_train / 255.0
X_test = test / 255.0
X_train = X_train.values.reshape(-1,28,28,1)
X_test = X_test.values.reshape(-1,28,28,1)
Y_train = to_categorical(Y_train, num_classes = 10)

# GLOBAL VARIABLES
annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)
styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']

nets = 3
# phyton syntax ersetlle Array der Länge 3 mit 0 initialisiert
model = [0] *nets

# For Number of Sub-sampling Layers
for j in range(3):
  # Initialisiere je ein sequentielles Modell ( Linear Stack of Layers )
  model[j] = Sequential()
  # Add Kernel Layer
  # 24 zu lernende Feature maps
  # Kernal Size = 5
  # Stride = 1 ->
  # Same Padding -> Aufweitung des Input images damit  Input Dimension = Output Dimension
  model[j].add( Conv2D(24,kernel_size=5,padding='same',activation='relu', input_shape=(28,28,1)) )
  # Add Pooling Layer
  # MAX Pooling, Welche Breite ?  --> P2 means max pooling using 2x2 filter and stride 2 -> Default (Stride -> increment der Maske)
  model[j].add(MaxPool2D())

  # --- In Sub Sampling Layer 2 und 3
  # 48 zu lernende Feature maps
  if j > 0:
     model[j].add(Conv2D(48,kernel_size=5,padding='same',activation='relu'))
     model[j].add(MaxPool2D())

  # --- In letzten Subsampling Layer
  if j > 1:
  # 64 zu lernende Feature maps
     model[j].add(Conv2D(64,kernel_size=5,padding='same',activation='relu'))
# hier mit Same Padding auf Pool
     model[j].add(MaxPool2D(padding='same'))

# Flatten um in MLP zu geben
model[j].add(Flatten())
# Dense Layer (Jedes Neuron bekommt Input von allen des Vorgänger Layers)
# ReLU = Rectified Linear activation Function
model[j].add(Dense(256, activation='relu'))
# Dense Layer (Jedes Neuron bekommt Input von allen des Vorgänger Layers)
# Softmax -> Normalisierung
model[j].add(Dense(10, activation='softmax'))
model[j].compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

# adam: https://keras.io/api/optimizers/adam/
Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.
# categorical_crossentropy
Computes the crossentropy loss between the labels and predictions.
Use this crossentropy loss function when there are two or more label classes.
# metrics=["accuracy"] -> Um Performance zu bewerten


# CREATE VALIDATION SET
X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.333)
# TRAIN NETWORKS
history = [0] * nets
names = ["(C-P)x1","(C-P)x2","(C-P)x3"]
epochs = 20
for j in range(nets):
history[j] = model[j].fit(X_train2,Y_train2, batch_size=80, epochs = epochs,
validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=0)
print("CNN {0}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}".format(
names[j],epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))



### Entwicklung:



### Probleme:

1. # Wie einen Dense Layer ?

sequentialBlock.add(Linear.builder().setUnits(denseLayerNeuronCount).build()).add(Activation.reluBlock());

3. # Beispiel Model Erstellung gefunden aber veraltet:

https://docs.djl.ai/docs/demos/malicious-url-detector/docs/define_model.html

Conv1D.Builder() Existiert nicht mehr
Activation.Builder() Existiert nicht mehr ...

Kann umgangen werden in dem man alte Version nutzt, Beispielsweise 0.2.1


3. # Expected layout: NCHW, but got: ???
-> Fehler bei trainer initialize

NCHW stands for:
batch N, channels C, depth D, height H, width W

        /*
        https://javadoc.io/doc/ai.djl/api/0.4.1/ai/djl/nn/convolutional/Conv2D.html
        The input to a Conv2D is an NDList with a single 4-D NDArray. The layout of the NDArray must be "NCHW".
        The shapes are
       ! data: (batch_size, channel, height, width) !
        Channel beispielsweise 3 := rgb, hier nur 1
        * */

trainer.initialize(new Shape(32,1,28,28));
anstelle von: trainer.initialize(new Shape(1,28,28));

5.  # Exception in thread "main" ai.djl.engine.EngineException: No deep learning engine found.
   --> Add Engine:  Example mnet and maven
   <dependency>
   <groupId>ai.djl.mxnet</groupId>
   <artifactId>mxnet-engine</artifactId>
   </dependency>

6. # Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 1
   at ai.djl.ndarray.types.Shape.get(Shape.java:138)
   at ai.djl.nn.convolutional.Convolution.getOutputShapes(Convolution.java:179)
   at ai.djl.nn.SequentialBlock.initializeChildBlocks(SequentialBlock.java:225)
   at ai.djl.nn.AbstractBaseBlock.initialize(AbstractBaseBlock.java:184)
   at ai.djl.training.Trainer.initialize(Trainer.java:118)
   at mnist.Experiment1Application.main(Experiment1Application.java:178)

        int size = endIndex - beginIndex;
        long[] out = new long[size];
        System.arraycopy(this.shape, beginIndex, out, 0, size); -> System.arraycopy([24,1,5], 2, [0], 0, 1);
--> BREAKPOINT im debugger -> size = 1 also eigentlich kein Problem

(Object src, int srcPos, Object dest, int destPos, int length)
--> kopiere 5 nach out index 0 eigentlich kein PROBLEM !!!!

--> Download Sources für besseres Debugging als mit Decompiler -->

    /*

    *     @Override
    public Shape[] getOutputShapes(Shape[] inputs) {
        long[] shape = new long[numDimensions()];
        shape[0] = inputs[0].get(0);
        shape[1] = filters;
        for (int i = 0; i < numDimensions() - 2; i++) {
            shape[2 + i] =
                    (inputs[0].get(2 + i)
                                            + 2 * padding.get(i) // TODO: HIER PROBLEM
                                            - dilation.get(i) * (kernelShape.get(i) - 1)
                                            - 1)
                                    / stride.get(i)
                            + 1;
        }
        return new Shape[] {new Shape(shape)};
    }

    // TODO: -> Shape in given dimension
    public long get(int dimension) {
        return shape[dimension];
    }

--> Ergebnis Shapes,Padding,Stride und co Brauchen Dimension 2.
Hier nicht default

Exception in thread "main" java.lang.IllegalArgumentException: kernelShape, Stride and Padding dimensions for maxPool2d should be 2

--> Selbes gilt somit auch nicht nur Für conv2d sondern auch die Pools
(Anmerkung im Falle der Pools wenigstens sehr gute Fehlermedlung, dies fehlt bei Conv2D Klasse)


7. # The Loss became NaN, try reduce learning rate,add clipGradient option to your optimizer, check input data and loss calculation.

--> Aus irgendeinem Grund hat Batchsize 32 -> 100 das Problem behoben
--> Später wieder aufgetreten -> Parameter änder notwendig


https://towardsdatascience.com/deep-java-library-djl-a-deep-learning-toolkit-for-java-developers-55d5a45bca7e
--> Params Probiert

8. # Wie setze ich diesen Annealer um Keras: LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)
https://analyticsindiamag.com/how-to-use-learning-rate-annealing-with-neural-networks/

LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)

LearningRateScheduler(schedule, verbose=0)

In new Keras API you can use more general version of schedule function which takes two arguments epoch and l r.
From docs:
schedule: a function that takes an epoch index as input (integer, indexed from 0)
and current learning rate and returns a new learning rate as output (float).

        lambda x: 1e-3 * 0.95 ** x,  // Hat aber nur einen Parameter ???

        ** in Phyton arithemtische auswertung


        MultiFactorTracker learningRateTracker = MultiFactorTracker
                .builder()
                .setSteps(steps)
                .optFactor(0.95f)
                .setBaseValue(1e-3f)
                .build();

Anderes Beispiel ->
LearningRateScheduler(lambda epoch: 1e-2 * (0.80 ** np.floor(epoch / 2)))
-> x ist current epoch -> learning rate irgendwo automatisch

--> Also anwendung bei jedem epoch

https://d2l.djl.ai/chapter_optimization/lr-scheduler.html#factor-tracker

9. # Es wäre wünschenswert wenn irgendwo erklärt worden wäre was numUpdate bei Tracker bedeutet

10. # Wie Softmax Activation ?
Activation.relu vorhanden aber nicht softmax
-> Untersuchung der Klasse Activation  in docs -> softmax nicht vorhanden

Schaue in Github Code um eigene Implementation zu schreiben:

https://github.com/deepjavalibrary/djl/blob/master/api/src/main/java/ai/djl/nn/Activation.java

public static Block seluBlock() {
# bekommt Funktion mit IN und OUT NDList sowie einen Bezeichner, für meine zwecke egal -> DEFAULT
return new LambdaBlock(Activation::selu, "SELU");
}

public static NDList selu(NDList arrays) {
# Erstelle NDList aus NDArray auf das die Funktion angewandt wurde
return new NDList(arrays.singletonOrThrow().getNDArrayInternal().selu());
}

https://github.com/deepjavalibrary/djl/blob/master/api/src/main/java/ai/djl/nn/LambdaBlock.java

public LambdaBlock(Function<NDList, NDList> lambda, String name) {
super(VERSION);
this.lambda = lambda;
this.name = name;
}

Untersuche: new NDList().singletonOrThrow().getNDArrayInternal()
--> untersützt auch kein softmax


## Um softmax Block zu implementieren:

Aus der Doku:
LambdaBlock is a Block with no parameters or children.
LambdaBlock allows converting any function that takes an NDList as input and returns an NDList into a parameter-less and child-less Block.

1. Erstelle Lambdablock und gebe Softmax implementation als Parameter !

NDList
   An NDList represents a sequence of NDArrays with names.
   Each NDArray in this list can optionally have a name. You can use the name to look up an NDArray in the NDList.

NDArray
--> Docs entdeckung NDArray verfügt über softmax implementation


### Javadoc instanz läd stets sehr langsam -> download erforderlich




### Problem: ImageFolder 3 Channel obwohl ich grey scale image brauche

--> Viel zu lange benötigt um:

 .optFlag(Image.Flag.GRAYSCALE) zu finden


        ImageFolder dataset = ImageFolder.builder()
                .setRepository(repository)
                .addTransform(new Resize(28, 28))
                .addTransform(new ToTensor())
                .setSampling(batchSize, false)
                .optFlag(Image.Flag.GRAYSCALE)
                .build();


Da sonst unklar was mit dem Flag möglich, auf tieferer Ebene ist  Image.Flag flag   aber oben  nur abstrakt Flag könnte alles sein
Finden nur möglich indem man implementierte Interfaces und Klassen durchsucht.


### Test auf Rechner mit starker gpu:

--> nicht automatisch erkannt wie beschrieben

### Teste verschiedene Engines:

[x] mxnet
[x] pytorch
--> Funktioniert, aber resultierende Modelle scheinbar nicht äquivalent da mit pytorch im ersten epoch loss -> NaN, während mxnet durchläuft
[x] tensorflow
- Windows  AMD Ryzen 7 4700U:
This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Exception in thread "main" java.lang.UnsupportedOperationException: Not supported for TensorFlow Engine
at ai.djl.tensorflow.engine.TfModel.setBlock(TfModel.java:158)
model.setBlock(sequentialBlock);





### Performance:

Architektur:                       x86_64
  CPU Operationsmodus:             32-bit, 64-bit
  Adressgrößen:                    39 bits physical, 48 bits virtual
  Byte-Reihenfolge:                Little Endian
CPU(s):                            16
  Liste der Online-CPU(s):         0-15
Anbieterkennung:                   GenuineIntel
  Modellname:                      Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz
    Prozessorfamilie:              6
    Modell:                        158
    Thread(s) pro Kern:            2
    Kern(e) pro Sockel:            8
    Sockel:                        1
    Stepping:                      12
    Maximale Taktfrequenz der CPU: 5000,0000
    Minimale Taktfrequenz der CPU: 800,0000
    BogoMIPS:                      7200.00
Virtualisierungsfunktionen:
  Virtualisierung:                 VT-x
Caches (Gesamtsumme):
  L1d:                             256 KiB (8 Instanzen)
  L1i:                             256 KiB (8 Instanzen)
  L2:                              2 MiB (8 Instanzen)
  L3:                              16 MiB (1 Instanz)
NUMA:
  NUMA-Knoten:                     1
  NUMA-Knoten0 CPU(s):             0-15


  # https://www.nvidia.com/content/DriverDownloads/confirmation.php?url=/XFree86/Linux-x86_64/525.60.11/NVIDIA-Linux-x86_64-525.60.11.run&lang=us&type=TITAN


Nvidia Driver update:

sudo sh NVIDIA-Linux-x86_64-525.60.11.run

compatibility yes
install yes
kernel modules yes
utiity yes
restart yes

sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/fedora36/x86_64/cuda-fedora36.repo
sudo dnf clean all
sudo dnf -y module install nvidia-driver:latest-dkms

Fehler:

Letzte Prüfung auf abgelaufene Metadaten: vor 0:00:39 am Sa 17 Dez 2022 15:44:55 CET.
Fehler:
 Problem: package xorg-x11-drv-nvidia-power-3:515.76-1.fc35.x86_64 requires xorg-x11-drv-nvidia(x86-64) = 3:515.76, but none of the providers can be installed
  - Problem mit installiertem Paket xorg-x11-drv-nvidia-power-3:515.76-1.fc35.x86_64
  - Paket nvidia-driver-3:525.60.13-1.fc36.x86_64 steht im Konflikt mit xorg-x11-drv-nvidia, das von xorg-x11-drv-nvidia-3:515.76-1.fc35.x86_64 bereitgestellt wird
  - Paket nvidia-driver-3:525.60.13-1.fc36.x86_64 macht xorg-x11-drv-nvidia obsolet, das von xorg-x11-drv-nvidia-3:515.76-1.fc35.x86_64 bereitgestellt wird
  - package xorg-x11-drv-nvidia-power-3:470.74-1.fc35.x86_64 requires xorg-x11-drv-nvidia(x86-64) = 3:470.74, but none of the providers can be installed
  - package xorg-x11-drv-nvidia-power-3:520.56.06-1.fc35.x86_64 requires xorg-x11-drv-nvidia(x86-64) = 3:520.56.06, but none of the providers can be installed
  - widersprüchliche Anforderungen
  - Paket xorg-x11-drv-nvidia-3:470.74-1.fc35.x86_64 wird durch modulare Filterung herausgefiltert
  - Paket xorg-x11-drv-nvidia-3:520.56.06-1.fc35.x86_64 wird durch modulare Filterung herausgefiltert
(Versuchen Sie '--allowerasing' zur Befehlszeile hinzuzufügen, um Pakete mit Konflikten zu ersetzen or '--skip-broken' to skip uninstallable packages)

LÖSUNG AUF EIGENE GEFAHR:

sudo dnf -y module install nvidia-driver:latest-dkms --allowerasing


sudo dnf -y install cuda --allowerasing

### install Cudnn
https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html

https://developer.nvidia.com/rdp/cudnn-archive

--> download cudnn

 >>>> := meine Variante -> andere allgemein Version muss je nach heruntergeladener angepasst werden

 tar -xvf cudnn-linux-x86_64-8.x.x.x_cudaX.X-archive.tar.xz
 >>>> tar -xvf cudnn-linux-x86_64-8.6.0.163_cuda11-archive.tar.xz

 sudo cp cudnn-*-archive/include/cudnn*.h /usr/local/cuda/include
 >>>> sudo cp cudnn-linux-x86_64-8.6.0.163_cuda11-archive/include/cudnn*.h /usr/local/cuda-10.1/targets/x86_64-linux/include

 sudo cp -P cudnn-*-archive/lib/libcudnn* /usr/local/cuda/lib64
 >>>> sudo cp -P cudnn-linux-x86_64-8.6.0.163_cuda11-archive/lib/libcudnn* /usr/local/cuda-10.1/targets/x86_64-linux/lib

 sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*
 >>>> sudo chmod a+r /usr/local/cuda-10.1/targets/x86_64-linux/include/cudnn*.h /usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudnn*

### install NCCL

https://developer.nvidia.com/nccl/nccl-download
>>> bei mir fedora OS agnostic installer

tar xvf nccl-<version>.txz
>>> tar xvf nccl-<version>.txz


### Docker variante

#### requirements:
- docker ad docker-compose on host pc
- install nvidia docker, see below

#### install nvidia-docker
curl -s -L https://nvidia.github.io/libnvidia-container/centos8/libnvidia-container.repo | sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo
sudo dnf install nvidia-docker2
sudo vi /etc/nvidia-container-runtime/config.toml
uncomment no-cgroups

READY TO GO



### UPDATE TODOS:

Hallo Alio,

[] #1 SOFTMAX
- [] IN WIKI INFO ÄNDERN !
mitunter bist du in eine kleine Falle getappt. Für die SoftMax Variante
des Cross Entropy Losses existieren (bescheuerterweise) mehrere Namen.
Categorial CE Loss ist quasi synonym mit SoftMax CE Loss verwendbar :)
Aber es ist gar nicht schlimm, dass du diese als eigene Schichten
realisiert hast -> dann sehen wir wie die Lösung gestaltet werden muss
(und dass es überhaupt möglich ist), falls mal etwas exotischeres
ausprogrammiert werden muss!
Für die Vollständigkeit - hier:
https://deeplearning4j.konduit.ai/v/en-1.0.0-beta7/operation-namespaces/loss
ist fast ganz unten das softmax CE loss für Multiclass (one hot)
Probleme, wie es beim MNIST vorliegt vom deeplearning4j.
Hier:
https://javadoc.io/doc/ai.djl/api/latest/ai/djl/training/loss/package-summary.html

Die loss-Funktionen von DJL auch mit der entsprechenden Klasse für
Softmax CE loss.

-->  zu softmax

[] #2 GPU TESTEN
- [] djl
- [] dl4j
@GPU: Traust du dir das zu, mal interessehalber zu versuchen die Systeme
zum Laufen zu bekommen? Falls du die Grafik dabei wegschießt ist nicht
super schlimm, denn an dem Rechner arbeitet momentan ohnehin niemand
außer dir. Im Zweifelsfall kommst du dann nicht mehr via nomachine drauf
sondern nur noch über ssh.
Interessant dabei wäre, ob du subjektiv/objektiv Unterschiede in der
Schwierigkeit der Ersteinrichtung festellen kannst. Wenn es gar nicht
klappt, weil das Ganze viel zu komplex war, ist das auch eine Aussage
(Spoilerwarnung: zumindest DJL funktioniert auf dem System aber
definitiv, nur die Einrichtung ist mitunter unangenehm)


--> GPU Test

[] #3 Doku nachhaltigkeit
- [] Datein,Projekte Links,
Die Dokumentation sieht schon sehr schön und vor allem nutzbringend aus.
Für die Nahhaltigkeit wäre es auf alle Fälle wichtig, wenn du die
relevanten Dateien bzw. Projekte direkt im wiki anhängst auch innerhalb
deines Artikels auf die dann lokalen Dateien verlinkst. Damit sind diese
für die Ewigkeit bei uns konserviert.
- [] Projekte hochladen
- []


[x] #4 Javadoc meiner Funktionen
- [x] djl
- [x] dl4j
Schau noch mal bitte über
Orthographie etc. des wiki Artikels sowie über die Vollständigkeit der
Codedokumentation (Javadoc) deiner Java Klassen.


[x] #5 static

Außerdem fiel mir auf,
dass du sehr oft mit static Methoden gearbeitet hast. Ist dies von
Templates abgeleitet oder woher kam das Vorgehen?

--> kein besonderer Grund da aufruf in Main und für simples Beispiel auslagerung in eigene Klasse verwirrend



